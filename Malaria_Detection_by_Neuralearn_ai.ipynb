{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananthrkulks/Ananthrkulks/blob/main/Malaria_Detection_by_Neuralearn_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNNxapz2yDHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D,Activation,Dropout, BatchNormalization,InputLayer # Fixed import\n",
        "from tensorflow.python.keras import Sequential,backend,optimizers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPARATION**"
      ],
      "metadata": {
        "id": "SN2LKR70aSPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_qUxS7FzG3N"
      },
      "outputs": [],
      "source": [
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files=True, split=['train'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFISz4PQz84V"
      },
      "outputs": [],
      "source": [
        "dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2plc6cN0IBz"
      },
      "outputs": [],
      "source": [
        "dataset_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET VISUALIZATION**"
      ],
      "metadata": {
        "id": "HAhr1Ebnacbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mD1wXqM0Nky"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files=True, split='train')\n",
        "\n",
        "TRAIN_RATIO = 0.6\n",
        "VAL_RATIO = 0.2\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "\n",
        "DATASET_SIZE = len(list(dataset))\n",
        "\n",
        "train_dataset = dataset.take(int(TRAIN_RATIO * DATASET_SIZE))\n",
        "val_test_dataset = dataset.skip(int(TRAIN_RATIO * DATASET_SIZE))\n",
        "val_dataset = val_test_dataset.take(int(VAL_RATIO * DATASET_SIZE))\n",
        "test_dataset = val_test_dataset.skip(int(VAL_RATIO * DATASET_SIZE))\n",
        "\n",
        "for i, (image, label) in enumerate(train_dataset.take(16)):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv7lYFE202CL"
      },
      "outputs": [],
      "source": [
        "dataset_info.features['label'].int2str(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu_OW9Wn6ykZ"
      },
      "source": [
        "**DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8FLmMco1yJr"
      },
      "outputs": [],
      "source": [
        "IM_SIZE = 224\n",
        "def resizing(image, label):\n",
        "  return tf.image.resize(image,(IM_SIZE,IM_SIZE))/255.0 , label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hyTApAhz7Bp7"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(resizing)\n",
        "val_dataset = val_dataset.map(resizing)\n",
        "test_dataset = test_dataset.map(resizing)\n",
        "\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL CREATION AND TRAINING**"
      ],
      "metadata": {
        "id": "IEO0rM3VarRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IM_SIZE = 224\n",
        "def resizing(image, label):\n",
        "  if image.shape.ndims == 2:\n",
        "    image = tf.expand_dims(image, axis=-1)\n",
        "  return tf.image.resize(image,(IM_SIZE,IM_SIZE))/255.0 , label"
      ],
      "metadata": {
        "id": "UgHQPMNnRmGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhonwif-7ysy"
      },
      "outputs": [],
      "source": [
        "for image, label in train_dataset.take(1):\n",
        "  print(image, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg1jwmJ77-_C"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhKShBWYvh82"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "val_dataset = val_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etnuz6x0viUV"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "test_dataset = test_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3Kv3qIioe7M"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "                             tf.keras.layers.Conv2D(filters = 6, kernel_size = 5, strides = 1, padding='valid',activation='sigmoid') # Corrected the typo here\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkBQz0gBkiFu"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)), # Use tf.keras.layers.InputLayer\n",
        "                             tf.keras.layers.Conv2D(filters = 6, kernel_size = 5, strides = 1, padding='valid', activation='sigmoid') # Corrected kernel_size\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnHt7yLhmiUy"
      },
      "outputs": [],
      "source": [
        "lenet_model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape=(IM_SIZE, IM_SIZE, 3)),\n",
        "    tf.keras.layers.Conv2D(filters=6, kernel_size=3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='valid', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(100, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(10, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(1, activation='sigmoid'),\n",
        "\n",
        "])\n",
        "\n",
        "lenet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1e2UBEjfBs4"
      },
      "outputs": [],
      "source": [
        "y_true = [0, 1, 0, 0]\n",
        "y_pred = [0.6, 0.51, 0.94, 1]\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "bce(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHGMLAbeuN8U"
      },
      "outputs": [],
      "source": [
        "lenet_model.compile(optimizer = Adam(learning_rate = 0.01),\n",
        "              loss = BinaryCrossentropy(),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8G7kd1rgxlJ"
      },
      "outputs": [],
      "source": [
        "history = lenet_model.fit(train_dataset,validation_data = val_dataset, epochs = 20, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL EVALUATION AND TESTING**"
      ],
      "metadata": {
        "id": "8zoIiBHqbGGz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFoDRiXAiRUx"
      },
      "outputs": [],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQEn7pTjxhWY"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzZhW3lIxmNf"
      },
      "outputs": [],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_accuracy', 'val_accuracy'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gcKsITjvP8PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.evaluate (test_dataset)"
      ],
      "metadata": {
        "id": "NCBF5QTNPoZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "AWelRi8DTLuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = val_test_dataset.skip(int(VAL_RATIO * DATASET_SIZE))"
      ],
      "metadata": {
        "id": "FIrnGauNMxlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "3GV1-ytzUR16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parasite_or_not(x):\n",
        "  if(x<0.5):\n",
        "    return 'Parasitized'\n",
        "  else:\n",
        "    return 'Uninfected'"
      ],
      "metadata": {
        "id": "5OjpmeKTV4vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(train_dataset.take(9)):\n",
        "\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image[0])\n",
        "    plt.title(str(parasite_or_not(label.numpy()[0])) + \":\" + str(parasite_or_not(lenet_model.predict(image)[0][0])))\n",
        "\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "fEv8IfL5YUlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING AND SAVING **"
      ],
      "metadata": {
        "id": "OQEBhRlzbRby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.save(\"tensorflow_env1.keras\")"
      ],
      "metadata": {
        "id": "531a0V8oGbhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.save(\"tensorflow_env1.h5\")"
      ],
      "metadata": {
        "id": "TDbwbI5PGeOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.save(\"lenet.h5\")"
      ],
      "metadata": {
        "id": "2vtR7Et4Qutg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.save(\"lenet.h5\")\n",
        "\n",
        "lenet_loaded_model = tf.keras.models.load_model(\"lenet.h5\")\n",
        "lenet_loaded_model.summary()"
      ],
      "metadata": {
        "id": "wm_JTgpoRDD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"weights\", exist_ok=True)\n",
        "lenet_model.save_weights(\"weights/lenet_weights.weights.h5\")"
      ],
      "metadata": {
        "id": "knZNZLihRb5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "kH4a3xqJV2fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/lenet.h5 /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "NNKzU1GAWHNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgeY7jcTXGZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}